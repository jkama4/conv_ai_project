{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "558c2342",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jaydenkm/workspaces/school/conversational_ai/final_project/.venv/lib/python3.13/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Cloning into '/Users/jaydenkm/workspaces/school/conversational_ai/final_project/src/final_project/data/dstc11-track5'...\n",
      "Cloning into '/Users/jaydenkm/workspaces/school/conversational_ai/final_project/src/final_project/data/dstc11-track5'...\n"
     ]
    }
   ],
   "source": [
    "from final_project.user_agent import UserAgent\n",
    "from final_project.assistant_agent import BaseAssistantAgent, RAGAssistantAgent\n",
    "\n",
    "from final_project import config, utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9ffb02ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "kb = utils.get_knowledge_base()\n",
    "hotel_kb = kb[\"hotel\"]\n",
    "restaurant_kb = kb[\"restaurant\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6297fc80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset({\n",
      "    features: ['messages'],\n",
      "    num_rows: 2798\n",
      "})\n"
     ]
    }
   ],
   "source": [
    "print(config.TEST_DS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b4e0e03a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llama_model_load_from_file_impl: using device Metal (Apple M4) - 18186 MiB free\n",
      "llama_model_loader: loaded meta data with 24 key-value pairs and 291 tensors from /Users/jaydenkm/.cache/huggingface/hub/models--TheBloke--Mistral-7B-Instruct-v0.2-GGUF/snapshots/3a6fbf4a41a1d52e415a4958cde6856d34b2db93/./mistral-7b-instruct-v0.2.Q4_K_M.gguf (version GGUF V3 (latest))\n",
      "llama_model_loader: Dumping metadata keys/values. Note: KV overrides do not apply in this output.\n",
      "llama_model_loader: - kv   0:                       general.architecture str              = llama\n",
      "llama_model_loader: - kv   1:                               general.name str              = mistralai_mistral-7b-instruct-v0.2\n",
      "llama_model_loader: - kv   2:                       llama.context_length u32              = 32768\n",
      "llama_model_loader: - kv   3:                     llama.embedding_length u32              = 4096\n",
      "llama_model_loader: - kv   4:                          llama.block_count u32              = 32\n",
      "llama_model_loader: - kv   5:                  llama.feed_forward_length u32              = 14336\n",
      "llama_model_loader: - kv   6:                 llama.rope.dimension_count u32              = 128\n",
      "llama_model_loader: - kv   7:                 llama.attention.head_count u32              = 32\n",
      "llama_model_loader: - kv   8:              llama.attention.head_count_kv u32              = 8\n",
      "llama_model_loader: - kv   9:     llama.attention.layer_norm_rms_epsilon f32              = 0.000010\n",
      "llama_model_loader: - kv  10:                       llama.rope.freq_base f32              = 1000000.000000\n",
      "llama_model_loader: - kv  11:                          general.file_type u32              = 15\n",
      "llama_model_loader: - kv  12:                       tokenizer.ggml.model str              = llama\n",
      "llama_model_loader: - kv  13:                      tokenizer.ggml.tokens arr[str,32000]   = [\"<unk>\", \"<s>\", \"</s>\", \"<0x00>\", \"<...\n",
      "llama_model_loader: - kv  14:                      tokenizer.ggml.scores arr[f32,32000]   = [0.000000, 0.000000, 0.000000, 0.0000...\n",
      "llama_model_loader: - kv  15:                  tokenizer.ggml.token_type arr[i32,32000]   = [2, 3, 3, 6, 6, 6, 6, 6, 6, 6, 6, 6, ...\n",
      "llama_model_loader: - kv  16:                tokenizer.ggml.bos_token_id u32              = 1\n",
      "llama_model_loader: - kv  17:                tokenizer.ggml.eos_token_id u32              = 2\n",
      "llama_model_loader: - kv  18:            tokenizer.ggml.unknown_token_id u32              = 0\n",
      "llama_model_loader: - kv  19:            tokenizer.ggml.padding_token_id u32              = 0\n",
      "llama_model_loader: - kv  20:               tokenizer.ggml.add_bos_token bool             = true\n",
      "llama_model_loader: - kv  21:               tokenizer.ggml.add_eos_token bool             = false\n",
      "llama_model_loader: - kv  22:                    tokenizer.chat_template str              = {{ bos_token }}{% for message in mess...\n",
      "llama_model_loader: - kv  23:               general.quantization_version u32              = 2\n",
      "llama_model_loader: - type  f32:   65 tensors\n",
      "llama_model_loader: - type q4_K:  193 tensors\n",
      "llama_model_loader: - type q6_K:   33 tensors\n",
      "print_info: file format = GGUF V3 (latest)\n",
      "print_info: file type   = Q4_K - Medium\n",
      "print_info: file size   = 4.07 GiB (4.83 BPW) \n",
      "init_tokenizer: initializing tokenizer for type 1\n",
      "load: control token:      2 '</s>' is not marked as EOG\n",
      "load: control token:      1 '<s>' is not marked as EOG\n",
      "load: special_eos_id is not in special_eog_ids - the tokenizer config may be incorrect\n",
      "load: printing all EOG tokens:\n",
      "load:   - 2 ('</s>')\n",
      "load: special tokens cache size = 3\n",
      "load: token to piece cache size = 0.1637 MB\n",
      "print_info: arch             = llama\n",
      "print_info: vocab_only       = 0\n",
      "print_info: n_ctx_train      = 32768\n",
      "print_info: n_embd           = 4096\n",
      "print_info: n_layer          = 32\n",
      "print_info: n_head           = 32\n",
      "print_info: n_head_kv        = 8\n",
      "print_info: n_rot            = 128\n",
      "print_info: n_swa            = 0\n",
      "print_info: is_swa_any       = 0\n",
      "print_info: n_embd_head_k    = 128\n",
      "print_info: n_embd_head_v    = 128\n",
      "print_info: n_gqa            = 4\n",
      "print_info: n_embd_k_gqa     = 1024\n",
      "print_info: n_embd_v_gqa     = 1024\n",
      "print_info: f_norm_eps       = 0.0e+00\n",
      "print_info: f_norm_rms_eps   = 1.0e-05\n",
      "print_info: f_clamp_kqv      = 0.0e+00\n",
      "print_info: f_max_alibi_bias = 0.0e+00\n",
      "print_info: f_logit_scale    = 0.0e+00\n",
      "print_info: f_attn_scale     = 0.0e+00\n",
      "print_info: n_ff             = 14336\n",
      "print_info: n_expert         = 0\n",
      "print_info: n_expert_used    = 0\n",
      "print_info: causal attn      = 1\n",
      "print_info: pooling type     = 0\n",
      "print_info: rope type        = 0\n",
      "print_info: rope scaling     = linear\n",
      "print_info: freq_base_train  = 1000000.0\n",
      "print_info: freq_scale_train = 1\n",
      "print_info: n_ctx_orig_yarn  = 32768\n",
      "print_info: rope_finetuned   = unknown\n",
      "print_info: model type       = 7B\n",
      "print_info: model params     = 7.24 B\n",
      "print_info: general.name     = mistralai_mistral-7b-instruct-v0.2\n",
      "print_info: vocab type       = SPM\n",
      "print_info: n_vocab          = 32000\n",
      "print_info: n_merges         = 0\n",
      "print_info: BOS token        = 1 '<s>'\n",
      "print_info: EOS token        = 2 '</s>'\n",
      "print_info: UNK token        = 0 '<unk>'\n",
      "print_info: PAD token        = 0 '<unk>'\n",
      "print_info: LF token         = 13 '<0x0A>'\n",
      "print_info: EOG token        = 2 '</s>'\n",
      "print_info: max token length = 48\n",
      "load_tensors: loading model tensors, this can take a while... (mmap = true)\n",
      "load_tensors: layer   0 assigned to device Metal, is_swa = 0\n",
      "load_tensors: layer   1 assigned to device Metal, is_swa = 0\n",
      "load_tensors: layer   2 assigned to device Metal, is_swa = 0\n",
      "load_tensors: layer   3 assigned to device Metal, is_swa = 0\n",
      "load_tensors: layer   4 assigned to device Metal, is_swa = 0\n",
      "load_tensors: layer   5 assigned to device Metal, is_swa = 0\n",
      "load_tensors: layer   6 assigned to device Metal, is_swa = 0\n",
      "load_tensors: layer   7 assigned to device Metal, is_swa = 0\n",
      "load_tensors: layer   8 assigned to device Metal, is_swa = 0\n",
      "load_tensors: layer   9 assigned to device Metal, is_swa = 0\n",
      "load_tensors: layer  10 assigned to device Metal, is_swa = 0\n",
      "load_tensors: layer  11 assigned to device Metal, is_swa = 0\n",
      "load_tensors: layer  12 assigned to device Metal, is_swa = 0\n",
      "load_tensors: layer  13 assigned to device Metal, is_swa = 0\n",
      "load_tensors: layer  14 assigned to device Metal, is_swa = 0\n",
      "load_tensors: layer  15 assigned to device Metal, is_swa = 0\n",
      "load_tensors: layer  16 assigned to device Metal, is_swa = 0\n",
      "load_tensors: layer  17 assigned to device Metal, is_swa = 0\n",
      "load_tensors: layer  18 assigned to device Metal, is_swa = 0\n",
      "load_tensors: layer  19 assigned to device Metal, is_swa = 0\n",
      "load_tensors: layer  20 assigned to device Metal, is_swa = 0\n",
      "load_tensors: layer  21 assigned to device Metal, is_swa = 0\n",
      "load_tensors: layer  22 assigned to device Metal, is_swa = 0\n",
      "load_tensors: layer  23 assigned to device Metal, is_swa = 0\n",
      "load_tensors: layer  24 assigned to device Metal, is_swa = 0\n",
      "load_tensors: layer  25 assigned to device Metal, is_swa = 0\n",
      "load_tensors: layer  26 assigned to device Metal, is_swa = 0\n",
      "load_tensors: layer  27 assigned to device Metal, is_swa = 0\n",
      "load_tensors: layer  28 assigned to device Metal, is_swa = 0\n",
      "load_tensors: layer  29 assigned to device Metal, is_swa = 0\n",
      "load_tensors: layer  30 assigned to device Metal, is_swa = 0\n",
      "load_tensors: layer  31 assigned to device Metal, is_swa = 0\n",
      "load_tensors: layer  32 assigned to device Metal, is_swa = 0\n",
      "load_tensors: tensor 'token_embd.weight' (q4_K) (and 0 others) cannot be used with preferred buffer type CPU_REPACK, using CPU instead\n",
      "ggml_backend_metal_log_allocated_size: allocated buffer, size =  4095.08 MiB, ( 4095.16 / 18186.25)\n",
      "load_tensors: offloading 32 repeating layers to GPU\n",
      "load_tensors: offloading output layer to GPU\n",
      "load_tensors: offloaded 33/33 layers to GPU\n",
      "load_tensors: Metal_Mapped model buffer size =  4095.07 MiB\n",
      "load_tensors:   CPU_Mapped model buffer size =    70.31 MiB\n",
      "..............................................................................................\n",
      "llama_context: constructing llama_context\n",
      "llama_context: n_seq_max     = 1\n",
      "llama_context: n_ctx         = 4096\n",
      "llama_context: n_ctx_per_seq = 4096\n",
      "llama_context: n_batch       = 512\n",
      "llama_context: n_ubatch      = 512\n",
      "llama_context: causal_attn   = 1\n",
      "llama_context: flash_attn    = 0\n",
      "llama_context: kv_unified    = false\n",
      "llama_context: freq_base     = 1000000.0\n",
      "llama_context: freq_scale    = 1\n",
      "llama_context: n_ctx_per_seq (4096) < n_ctx_train (32768) -- the full capacity of the model will not be utilized\n",
      "ggml_metal_init: allocating\n",
      "ggml_metal_init: found device: Apple M4\n",
      "ggml_metal_init: picking default device: Apple M4\n",
      "ggml_metal_load_library: using embedded metal library\n",
      "ggml_metal_init: GPU name:   Apple M4\n",
      "ggml_metal_init: GPU family: MTLGPUFamilyApple9  (1009)\n",
      "ggml_metal_init: GPU family: MTLGPUFamilyCommon3 (3003)\n",
      "ggml_metal_init: GPU family: MTLGPUFamilyMetal4  (5002)\n",
      "ggml_metal_init: simdgroup reduction   = true\n",
      "ggml_metal_init: simdgroup matrix mul. = true\n",
      "ggml_metal_init: has residency sets    = true\n",
      "ggml_metal_init: has bfloat            = true\n",
      "ggml_metal_init: use bfloat            = false\n",
      "ggml_metal_init: hasUnifiedMemory      = true\n",
      "ggml_metal_init: recommendedMaxWorkingSetSize  = 19069.67 MB\n",
      "ggml_metal_init: loaded kernel_add                                    0x10316c8f0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_add_fuse_2                             0x10316d0f0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_add_fuse_3                             0x10316d8f0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_add_fuse_4                             0x10316e0f0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_add_fuse_5                             0x10316e3f0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_add_fuse_6                             0x10316e6f0 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_add_fuse_7                             0x8b71d4000 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_add_fuse_8                             0x8b71d4300 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_add_row_c4                             0x8b71d4600 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_add_row_c4_fuse_2                      0x8b71d4900 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_add_row_c4_fuse_3                      0x8b71d4c00 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_add_row_c4_fuse_4                      0x8b71d4f00 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_add_row_c4_fuse_5                      0x8b71d5200 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_add_row_c4_fuse_6                      0x8b71d5500 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_add_row_c4_fuse_7                      0x8b71d5800 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_add_row_c4_fuse_8                      0x8b71d5b00 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_sub                                    0x8b71d5e00 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_sub_row_c4                             0x8b71d6100 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul                                    0x8b71d6400 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_row_c4                             0x8b71d6700 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_div                                    0x8b71d6a00 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_div_row_c4                             0x8b71d6d00 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_add_id                                 0x8b71d7000 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_repeat_f32                             0x8b71d7300 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_repeat_f16                             0x8b71d7600 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_repeat_i32                             0x8b71d7900 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_repeat_i16                             0x8b71d7c00 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_scale                                  0x8b720c000 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_scale_4                                0x8b720c300 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_clamp                                  0x8b720c600 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_tanh                                   0x8b720c900 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_relu                                   0x8b720cc00 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_sigmoid                                0x8b720cf00 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_gelu                                   0x8b720d200 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_gelu_4                                 0x8b720d500 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_gelu_erf                               0x8b720d800 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_gelu_erf_4                             0x8b720db00 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_gelu_quick                             0x8b720de00 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_gelu_quick_4                           0x8b720e100 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_silu                                   0x8b720e400 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_silu_4                                 0x8b720e700 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_elu                                    0x8b720ea00 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_abs                                    0x8b720ed00 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_sgn                                    0x8b720f000 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_step                                   0x8b720f300 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_hardswish                              0x8b720f600 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_hardsigmoid                            0x8b720f900 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_exp                                    0x8b720fc00 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_soft_max_f16                           0x8b7238000 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_soft_max_f16_4                         0x8b7238300 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_soft_max_f32                           0x8b7238600 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_soft_max_f32_4                         0x8b7238900 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_diag_mask_inf                          0x8b7238c00 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_diag_mask_inf_8                        0x8b7238f00 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_get_rows_f32                           0x8b7239200 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_get_rows_f16                           0x8b7239500 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: skipping kernel_get_rows_bf16                     (not supported)\n",
      "ggml_metal_init: loaded kernel_get_rows_q4_0                          0x8b7239800 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_get_rows_q4_1                          0x8b7239b00 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_get_rows_q5_0                          0x8b7239e00 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_get_rows_q5_1                          0x8b723a100 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_get_rows_q8_0                          0x8b723a400 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_get_rows_mxfp4                         0x8b723a700 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_get_rows_q2_K                          0x8b723aa00 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_get_rows_q3_K                          0x8b723ad00 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_get_rows_q4_K                          0x8b723b000 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_get_rows_q5_K                          0x8b723b300 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_get_rows_q6_K                          0x8b723b600 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_get_rows_iq2_xxs                       0x8b723b900 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_get_rows_iq2_xs                        0x8b723bc00 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_get_rows_iq3_xxs                       0x8b7260000 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_get_rows_iq3_s                         0x8b7260300 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_get_rows_iq2_s                         0x8b7260600 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_get_rows_iq1_s                         0x8b7260900 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_get_rows_iq1_m                         0x8b7260c00 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_get_rows_iq4_nl                        0x8b7260f00 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_get_rows_iq4_xs                        0x8b7261200 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_get_rows_i32                           0x8b7261500 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_set_rows_f32                           0x8b7261800 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_set_rows_f16                           0x8b7261b00 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: skipping kernel_set_rows_bf16                     (not supported)\n",
      "ggml_metal_init: loaded kernel_set_rows_q8_0                          0x8b7261e00 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_set_rows_q4_0                          0x8b7262100 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_set_rows_q4_1                          0x8b7262400 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_set_rows_q5_0                          0x8b7262700 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_set_rows_q5_1                          0x8b7262a00 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_set_rows_iq4_nl                        0x8b7262d00 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_rms_norm                               0x8b7263000 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_rms_norm_mul                           0x8b7263300 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_rms_norm_mul_add                       0x8b7263600 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_l2_norm                                0x8b7263900 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_group_norm                             0x8b7263c00 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_norm                                   0x8b7288000 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_ssm_conv_f32                           0x8b7288300 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_ssm_scan_f32                           0x8b7288600 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_ssm_scan_f32_group                     0x8b7288900 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_rwkv_wkv6_f32                          0x8b7288c00 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_rwkv_wkv7_f32                          0x8b7288f00 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_f32_f32                         0x8b7289200 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_f32_f32_c4                      0x8b7289500 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: skipping kernel_mul_mv_bf16_f32                   (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mv_bf16_f32_c4                (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mv_bf16_f32_1row              (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mv_bf16_f32_l4                (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mv_bf16_bf16                  (not supported)\n",
      "ggml_metal_init: loaded kernel_mul_mv_f16_f32                         0x8b7289800 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_f16_f32_c4                      0x8b7289b00 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_f16_f32_1row                    0x8b7289e00 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_f16_f32_l4                      0x8b728a100 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_f16_f16                         0x8b728a400 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_q4_0_f32                        0x8b728a700 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_q4_1_f32                        0x8b728aa00 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_q5_0_f32                        0x8b728ad00 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_q5_1_f32                        0x8b728b000 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_q8_0_f32                        0x8b728b300 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_mxfp4_f32                       0x8b728b600 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_ext_f16_f32_r1_2                0x8b728b900 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_ext_f16_f32_r1_3                0x8b728bc00 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_ext_f16_f32_r1_4                0x8b72b8000 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_ext_f16_f32_r1_5                0x8b72b8300 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_ext_q4_0_f32_r1_2               0x8b72b8600 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_ext_q4_0_f32_r1_3               0x8b72b8900 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_ext_q4_0_f32_r1_4               0x8b72b8c00 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_ext_q4_0_f32_r1_5               0x8b72b8f00 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_ext_q4_1_f32_r1_2               0x8b72b9200 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_ext_q4_1_f32_r1_3               0x8b72b9500 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_ext_q4_1_f32_r1_4               0x8b72b9800 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_ext_q4_1_f32_r1_5               0x8b72b9b00 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_ext_q5_0_f32_r1_2               0x8b72b9e00 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_ext_q5_0_f32_r1_3               0x8b72ba100 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_ext_q5_0_f32_r1_4               0x8b72ba400 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_ext_q5_0_f32_r1_5               0x8b72ba700 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_ext_q5_1_f32_r1_2               0x8b72baa00 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_ext_q5_1_f32_r1_3               0x8b72bad00 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_ext_q5_1_f32_r1_4               0x8b72bb000 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_ext_q5_1_f32_r1_5               0x8b72bb300 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_ext_q8_0_f32_r1_2               0x8b72bb600 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_ext_q8_0_f32_r1_3               0x8b72bb900 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_ext_q8_0_f32_r1_4               0x8b72bbc00 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_ext_q8_0_f32_r1_5               0x8b72c4000 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_ext_mxfp4_f32_r1_2              0x8b72c4300 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_ext_mxfp4_f32_r1_3              0x8b72c4600 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_ext_mxfp4_f32_r1_4              0x8b72c4900 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_ext_mxfp4_f32_r1_5              0x8b72c4c00 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_ext_q4_K_f32_r1_2               0x8b72c4f00 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_ext_q4_K_f32_r1_3               0x8b72c5200 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_ext_q4_K_f32_r1_4               0x8b72c5500 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_ext_q4_K_f32_r1_5               0x8b72c5800 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_ext_q5_K_f32_r1_2               0x8b72c5b00 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_ext_q5_K_f32_r1_3               0x8b72c5e00 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_ext_q5_K_f32_r1_4               0x8b72c6100 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_ext_q5_K_f32_r1_5               0x8b72c6400 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_ext_q6_K_f32_r1_2               0x8b72c6700 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_ext_q6_K_f32_r1_3               0x8b72c6a00 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_ext_q6_K_f32_r1_4               0x8b72c6d00 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_ext_q6_K_f32_r1_5               0x8b72c7000 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_ext_iq4_nl_f32_r1_2             0x8b72c7300 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_ext_iq4_nl_f32_r1_3             0x8b72c7600 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_ext_iq4_nl_f32_r1_4             0x8b72c7900 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_ext_iq4_nl_f32_r1_5             0x8b72c7c00 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_q2_K_f32                        0x8b2460000 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_q3_K_f32                        0x8b2460300 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_q4_K_f32                        0x8b2460600 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_q5_K_f32                        0x8b2460900 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_q6_K_f32                        0x8b2460c00 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_iq2_xxs_f32                     0x8b2460f00 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_iq2_xs_f32                      0x8b2461200 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_iq3_xxs_f32                     0x8b2461500 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_iq3_s_f32                       0x8b2461800 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_iq2_s_f32                       0x8b2461b00 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_iq1_s_f32                       0x8b2461e00 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_iq1_m_f32                       0x8b2462100 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_iq4_nl_f32                      0x8b2462400 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_iq4_xs_f32                      0x8b2462700 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_id_f32_f32                      0x8b2462a00 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_id_f16_f32                      0x8b2462d00 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: skipping kernel_mul_mv_id_bf16_f32                (not supported)\n",
      "ggml_metal_init: loaded kernel_mul_mv_id_q4_0_f32                     0x8b2463000 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_id_q4_1_f32                     0x8b2463300 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_id_q5_0_f32                     0x8b2463600 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_id_q5_1_f32                     0x8b2463900 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_id_q8_0_f32                     0x8b2463c00 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_id_mxfp4_f32                    0x8b7334000 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_id_q2_K_f32                     0x8b7334300 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_id_q3_K_f32                     0x8b7334600 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_id_q4_K_f32                     0x8b7334900 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_id_q5_K_f32                     0x8b7334c00 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_id_q6_K_f32                     0x8b7334f00 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_id_iq2_xxs_f32                  0x8b7335200 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_id_iq2_xs_f32                   0x8b7335500 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_id_iq3_xxs_f32                  0x8b7335800 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_id_iq3_s_f32                    0x8b7335b00 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_id_iq2_s_f32                    0x8b7335e00 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_id_iq1_s_f32                    0x8b7336100 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_id_iq1_m_f32                    0x8b7336400 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_id_iq4_nl_f32                   0x8b7336700 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mv_id_iq4_xs_f32                   0x8b7336a00 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mm_f32_f32                         0x8b7336d00 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mm_f16_f32                         0x8b7337000 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: skipping kernel_mul_mm_bf16_f32                   (not supported)\n",
      "ggml_metal_init: loaded kernel_mul_mm_q4_0_f32                        0x8b7337300 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mm_q4_1_f32                        0x8b7337600 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mm_q5_0_f32                        0x8b7337900 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mm_q5_1_f32                        0x8b7337c00 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mm_q8_0_f32                        0x8b7368000 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mm_mxfp4_f32                       0x8b7368300 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mm_mxfp4_f32                       0x8b7368600 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mm_q2_K_f32                        0x8b7368900 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mm_q3_K_f32                        0x8b7368c00 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mm_q4_K_f32                        0x8b7368f00 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mm_q5_K_f32                        0x8b7369200 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mm_q6_K_f32                        0x8b7369500 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mm_iq2_xxs_f32                     0x8b7369800 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mm_iq2_xs_f32                      0x8b7369b00 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mm_iq3_xxs_f32                     0x8b7369e00 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mm_iq3_s_f32                       0x8b736a100 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mm_iq2_s_f32                       0x8b736a400 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mm_iq1_s_f32                       0x8b736a700 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mm_iq1_m_f32                       0x8b736aa00 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mm_iq4_nl_f32                      0x8b736ad00 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mm_iq4_xs_f32                      0x8b736b000 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mm_id_map0_f16                     0x8b736b300 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mm_id_map1_f32                     0x8b736b600 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mm_id_f32_f16                      0x8b736b900 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mm_id_f16_f16                      0x8b736bc00 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: skipping kernel_mul_mm_id_bf16_f16                (not supported)\n",
      "ggml_metal_init: loaded kernel_mul_mm_id_q4_0_f16                     0x8b7390000 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mm_id_q4_1_f16                     0x8b7390300 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mm_id_q5_0_f16                     0x8b7390600 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mm_id_q5_1_f16                     0x8b7390900 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mm_id_q8_0_f16                     0x8b7390c00 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mm_id_mxfp4_f16                    0x8b7390f00 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mm_id_q2_K_f16                     0x8b7391200 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mm_id_q3_K_f16                     0x8b7391500 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mm_id_q4_K_f16                     0x8b7391800 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mm_id_q5_K_f16                     0x8b7391b00 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mm_id_q6_K_f16                     0x8b7391e00 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mm_id_iq2_xxs_f16                  0x8b7392100 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mm_id_iq2_xs_f16                   0x8b7392400 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mm_id_iq3_xxs_f16                  0x8b7392700 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mm_id_iq3_s_f16                    0x8b7392a00 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mm_id_iq2_s_f16                    0x8b7392d00 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mm_id_iq1_s_f16                    0x8b7393000 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mm_id_iq1_m_f16                    0x8b7393300 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mm_id_iq4_nl_f16                   0x8b7393600 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mul_mm_id_iq4_xs_f16                   0x8b7393900 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_rope_norm_f32                          0x8b7393c00 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_rope_norm_f16                          0x8b73b4000 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_rope_multi_f32                         0x8b73b4300 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_rope_multi_f16                         0x8b73b4600 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_rope_vision_f32                        0x8b73b4900 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_rope_vision_f16                        0x8b73b4c00 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_rope_neox_f32                          0x8b73b4f00 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_rope_neox_f16                          0x8b73b5200 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_im2col_f16                             0x8b73b5500 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_im2col_f32                             0x8b73b5800 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_im2col_ext_f16                         0x8b73b5b00 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_im2col_ext_f32                         0x8b73b5e00 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_conv_transpose_1d_f32_f32              0x8b73b6100 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_conv_transpose_1d_f16_f32              0x8b73b6400 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_upscale_f32                            0x8b73b6700 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_pad_f32                                0x8b73b6a00 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_pad_reflect_1d_f32                     0x8b73b6d00 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_timestep_embedding_f32                 0x8b73b7000 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_arange_f32                             0x8b73b7300 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_argsort_f32_i32_asc                    0x8b73b7600 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_argsort_f32_i32_desc                   0x8b73b7900 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_leaky_relu_f32                         0x8b73b7c00 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_f16_h64                 0x8b73c0000 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_f16_h80                 0x8b73c0300 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_f16_h96                 0x8b73c0600 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_f16_h112                0x8b73c0900 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_f16_h128                0x8b73c0c00 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_f16_h192                0x8b73c0f00 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_f16_hk192_hv128         0x8b73c1200 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_f16_h256                0x8b73c1500 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_f16_hk576_hv512         0x8b73c1800 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_bf16_h64           (not supported)\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_bf16_h80           (not supported)\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_bf16_h96           (not supported)\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_bf16_h112          (not supported)\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_bf16_h128          (not supported)\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_bf16_h192          (not supported)\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_bf16_hk192_hv128   (not supported)\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_bf16_h256          (not supported)\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_bf16_hk576_hv512   (not supported)\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_q4_0_h64                0x8b73c1b00 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_q4_0_h80                0x8b73c1e00 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_q4_0_h96                0x8b73c2100 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_q4_0_h112               0x8b73c2400 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_q4_0_h128               0x8b73c2700 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_q4_0_h192               0x8b73c2a00 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_q4_0_hk192_hv128        0x8b73c2d00 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_q4_0_h256               0x8b73c3000 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_q4_0_hk576_hv512        0x8b73c3300 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_q4_1_h64                0x8b73c3600 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_q4_1_h80                0x8b73c3900 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_q4_1_h96                0x8b73c3c00 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_q4_1_h112               0x8b73dc000 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_q4_1_h128               0x8b73dc300 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_q4_1_h192               0x8b73dc600 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_q4_1_hk192_hv128        0x8b73dc900 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_q4_1_h256               0x8b73dcc00 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_q4_1_hk576_hv512        0x8b73dcf00 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_q5_0_h64                0x8b73dd200 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_q5_0_h80                0x8b73dd500 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_q5_0_h96                0x8b73dd800 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_q5_0_h112               0x8b73ddb00 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_q5_0_h128               0x8b73dde00 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_q5_0_h192               0x8b73de100 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_q5_0_hk192_hv128        0x8b73de400 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_q5_0_h256               0x8b73de700 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_q5_0_hk576_hv512        0x8b73dea00 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_q5_1_h64                0x8b73ded00 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_q5_1_h80                0x8b73df000 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_q5_1_h96                0x8b73df300 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_q5_1_h112               0x8b73df600 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_q5_1_h128               0x8b73df900 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_q5_1_h192               0x8b73dfc00 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_q5_1_hk192_hv128        0x8b73f4000 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_q5_1_h256               0x8b73f4300 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_q5_1_hk576_hv512        0x8b73f4600 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_q8_0_h64                0x8b73f4900 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_q8_0_h80                0x8b73f4c00 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_q8_0_h96                0x8b73f4f00 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_q8_0_h112               0x8b73f5200 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_q8_0_h128               0x8b73f5500 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_q8_0_h192               0x8b73f5800 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_q8_0_hk192_hv128        0x8b73f5b00 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_q8_0_h256               0x8b73f5e00 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_q8_0_hk576_hv512        0x8b73f6100 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_vec_f16_h64             0x8b73f6400 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_vec_bf16_h64       (not supported)\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_vec_q4_0_h64            0x8b73f6700 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_vec_q4_1_h64            0x8b73f6a00 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_vec_q5_0_h64            0x8b73f6d00 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_vec_q5_1_h64            0x8b73f7000 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_vec_q8_0_h64            0x8b73f7300 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_vec_f16_h96             0x8b73f7600 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_vec_bf16_h96       (not supported)\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_vec_q4_0_h96            0x8b73f7900 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_vec_q4_1_h96            0x8b73f7c00 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_vec_q5_0_h96            0x8b744c000 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_vec_q5_1_h96            0x8b744c300 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_vec_q8_0_h96            0x8b744c600 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_vec_f16_h128            0x8b744c900 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_vec_bf16_h128      (not supported)\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_vec_q4_0_h128           0x8b744cc00 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_vec_q4_1_h128           0x8b744cf00 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_vec_q5_0_h128           0x8b744d200 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_vec_q5_1_h128           0x8b744d500 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_vec_q8_0_h128           0x8b744d800 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_vec_f16_h192            0x8b744db00 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_vec_bf16_h192      (not supported)\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_vec_q4_0_h192           0x8b744de00 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_vec_q4_1_h192           0x8b744e100 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_vec_q5_0_h192           0x8b744e400 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_vec_q5_1_h192           0x8b744e700 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_vec_q8_0_h192           0x8b744ea00 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_vec_f16_hk192_hv128      0x8b744ed00 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_vec_bf16_hk192_hv128 (not supported)\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_vec_q4_0_hk192_hv128      0x8b744f000 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_vec_q4_1_hk192_hv128      0x8b744f300 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_vec_q5_0_hk192_hv128      0x8b744f600 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_vec_q5_1_hk192_hv128      0x8b744f900 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_vec_q8_0_hk192_hv128      0x8b744fc00 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_vec_f16_h256            0x8b748c000 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_vec_bf16_h256      (not supported)\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_vec_q4_0_h256           0x8b748c300 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_vec_q4_1_h256           0x8b748c600 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_vec_q5_0_h256           0x8b748c900 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_vec_q5_1_h256           0x8b748cc00 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_vec_q8_0_h256           0x8b748cf00 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_vec_f16_hk576_hv512      0x8b748d200 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_vec_bf16_hk576_hv512 (not supported)\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_vec_q4_0_hk576_hv512      0x8b748d500 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_vec_q4_1_hk576_hv512      0x8b748d800 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_vec_q5_0_hk576_hv512      0x8b748db00 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_vec_q5_1_hk576_hv512      0x8b748de00 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_flash_attn_ext_vec_q8_0_hk576_hv512      0x8b748e100 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_set_f32                                0x8b748e400 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_set_i32                                0x8b748e700 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_cpy_f32_f32                            0x8b748ea00 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_cpy_f32_f16                            0x8b748ed00 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: skipping kernel_cpy_f32_bf16                      (not supported)\n",
      "ggml_metal_init: loaded kernel_cpy_f16_f32                            0x8b748f000 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_cpy_f16_f16                            0x8b748f300 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: skipping kernel_cpy_bf16_f32                      (not supported)\n",
      "ggml_metal_init: skipping kernel_cpy_bf16_bf16                     (not supported)\n",
      "ggml_metal_init: loaded kernel_cpy_f32_q8_0                           0x8b748f600 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_cpy_f32_q4_0                           0x8b748f900 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_cpy_f32_q4_1                           0x8b748fc00 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_cpy_f32_q5_0                           0x8b74bc000 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_cpy_f32_q5_1                           0x8b74bc300 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_cpy_f32_iq4_nl                         0x8b74bc600 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_cpy_q4_0_f32                           0x8b74bc900 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_cpy_q4_0_f16                           0x8b74bcc00 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_cpy_q4_1_f32                           0x8b74bcf00 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_cpy_q4_1_f16                           0x8b74bd200 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_cpy_q5_0_f32                           0x8b74bd500 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_cpy_q5_0_f16                           0x8b74bd800 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_cpy_q5_1_f32                           0x8b74bdb00 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_cpy_q5_1_f16                           0x8b74bde00 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_cpy_q8_0_f32                           0x8b74be100 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_cpy_q8_0_f16                           0x8b74be400 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_concat                                 0x8b74be700 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_sqr                                    0x8b74bea00 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_sqrt                                   0x8b74bed00 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_sin                                    0x8b74bf000 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_cos                                    0x8b74bf300 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_neg                                    0x8b74bf600 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_reglu                                  0x8b74bf900 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_geglu                                  0x8b74bfc00 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_swiglu                                 0x8b74c4000 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_swiglu_oai                             0x8b74c4300 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_geglu_erf                              0x8b74c4600 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_geglu_quick                            0x8b74c4900 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_sum_rows                               0x8b74c4c00 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_mean                                   0x8b74c4f00 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_argmax                                 0x8b74c5200 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_pool_2d_avg_f32                        0x8b74c5500 | th_max = 1024 | th_width =   32\n",
      "ggml_metal_init: loaded kernel_pool_2d_max_f32                        0x8b74c5800 | th_max = 1024 | th_width =   32\n",
      "set_abort_callback: call\n",
      "llama_context:        CPU  output buffer size =     0.12 MiB\n",
      "create_memory: n_ctx = 4096 (padded)\n",
      "llama_kv_cache_unified: layer   0: dev = Metal\n",
      "llama_kv_cache_unified: layer   1: dev = Metal\n",
      "llama_kv_cache_unified: layer   2: dev = Metal\n",
      "llama_kv_cache_unified: layer   3: dev = Metal\n",
      "llama_kv_cache_unified: layer   4: dev = Metal\n",
      "llama_kv_cache_unified: layer   5: dev = Metal\n",
      "llama_kv_cache_unified: layer   6: dev = Metal\n",
      "llama_kv_cache_unified: layer   7: dev = Metal\n",
      "llama_kv_cache_unified: layer   8: dev = Metal\n",
      "llama_kv_cache_unified: layer   9: dev = Metal\n",
      "llama_kv_cache_unified: layer  10: dev = Metal\n",
      "llama_kv_cache_unified: layer  11: dev = Metal\n",
      "llama_kv_cache_unified: layer  12: dev = Metal\n",
      "llama_kv_cache_unified: layer  13: dev = Metal\n",
      "llama_kv_cache_unified: layer  14: dev = Metal\n",
      "llama_kv_cache_unified: layer  15: dev = Metal\n",
      "llama_kv_cache_unified: layer  16: dev = Metal\n",
      "llama_kv_cache_unified: layer  17: dev = Metal\n",
      "llama_kv_cache_unified: layer  18: dev = Metal\n",
      "llama_kv_cache_unified: layer  19: dev = Metal\n",
      "llama_kv_cache_unified: layer  20: dev = Metal\n",
      "llama_kv_cache_unified: layer  21: dev = Metal\n",
      "llama_kv_cache_unified: layer  22: dev = Metal\n",
      "llama_kv_cache_unified: layer  23: dev = Metal\n",
      "llama_kv_cache_unified: layer  24: dev = Metal\n",
      "llama_kv_cache_unified: layer  25: dev = Metal\n",
      "llama_kv_cache_unified: layer  26: dev = Metal\n",
      "llama_kv_cache_unified: layer  27: dev = Metal\n",
      "llama_kv_cache_unified: layer  28: dev = Metal\n",
      "llama_kv_cache_unified: layer  29: dev = Metal\n",
      "llama_kv_cache_unified: layer  30: dev = Metal\n",
      "llama_kv_cache_unified: layer  31: dev = Metal\n",
      "llama_kv_cache_unified:      Metal KV buffer size =   512.00 MiB\n",
      "llama_kv_cache_unified: size =  512.00 MiB (  4096 cells,  32 layers,  1/1 seqs), K (f16):  256.00 MiB, V (f16):  256.00 MiB\n",
      "llama_context: enumerating backends\n",
      "llama_context: backend_ptrs.size() = 3\n",
      "llama_context: max_nodes = 2328\n",
      "llama_context: worst-case: n_tokens = 512, n_seqs = 1, n_outputs = 0\n",
      "graph_reserve: reserving a graph for ubatch with n_tokens =  512, n_seqs =  1, n_outputs =  512\n",
      "graph_reserve: reserving a graph for ubatch with n_tokens =    1, n_seqs =  1, n_outputs =    1\n",
      "graph_reserve: reserving a graph for ubatch with n_tokens =  512, n_seqs =  1, n_outputs =  512\n",
      "llama_context:      Metal compute buffer size =   300.01 MiB\n",
      "llama_context:        CPU compute buffer size =    20.01 MiB\n",
      "llama_context: graph nodes  = 1126\n",
      "llama_context: graph splits = 2\n",
      "Metal : EMBED_LIBRARY = 1 | CPU : NEON = 1 | ARM_FMA = 1 | FP16_VA = 1 | MATMUL_INT8 = 1 | DOTPROD = 1 | SME = 1 | ACCELERATE = 1 | REPACK = 1 | \n",
      "Model metadata: {'general.quantization_version': '2', 'tokenizer.chat_template': \"{{ bos_token }}{% for message in messages %}{% if (message['role'] == 'user') != (loop.index0 % 2 == 0) %}{{ raise_exception('Conversation roles must alternate user/assistant/user/assistant/...') }}{% endif %}{% if message['role'] == 'user' %}{{ '[INST] ' + message['content'] + ' [/INST]' }}{% elif message['role'] == 'assistant' %}{{ message['content'] + eos_token}}{% else %}{{ raise_exception('Only user and assistant roles are supported!') }}{% endif %}{% endfor %}\", 'tokenizer.ggml.add_eos_token': 'false', 'tokenizer.ggml.add_bos_token': 'true', 'tokenizer.ggml.padding_token_id': '0', 'tokenizer.ggml.unknown_token_id': '0', 'tokenizer.ggml.eos_token_id': '2', 'tokenizer.ggml.bos_token_id': '1', 'tokenizer.ggml.model': 'llama', 'llama.attention.head_count_kv': '8', 'llama.context_length': '32768', 'llama.attention.head_count': '32', 'llama.rope.freq_base': '1000000.000000', 'llama.rope.dimension_count': '128', 'general.file_type': '15', 'llama.feed_forward_length': '14336', 'llama.embedding_length': '4096', 'llama.block_count': '32', 'general.architecture': 'llama', 'llama.attention.layer_norm_rms_epsilon': '0.000010', 'general.name': 'mistralai_mistral-7b-instruct-v0.2'}\n",
      "Available chat formats from metadata: chat_template.default\n",
      "Guessed chat format: mistral-instruct\n",
      "Loading checkpoint shards: 100%|| 2/2 [00:03<00:00,  1.77s/it]\n"
     ]
    }
   ],
   "source": [
    "user_agent = UserAgent(persona=\"adventurous\")\n",
    "assistant_agent = BaseAssistantAgent()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d305586c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'content': 'You are a helpful travel assistant.', 'role': 'system'},\n",
       " {'content': \"I'm looking to stay at a 3 star hotel in the north.\",\n",
       "  'role': 'user'},\n",
       " {'content': 'Sorry, I have no results for that query. Would you like to try a different area of town?',\n",
       "  'role': 'assistant'},\n",
       " {'content': 'Are there any moderate priced hotels in the North?',\n",
       "  'role': 'user'},\n",
       " {'content': 'Yes I have two. Would you like me to book one?',\n",
       "  'role': 'assistant'},\n",
       " {'content': 'I need a hotel to include free parking; does either have that?',\n",
       "  'role': 'user'},\n",
       " {'content': 'Yes both of them have free parking.', 'role': 'assistant'},\n",
       " {'content': 'Which one would you recommend?', 'role': 'user'},\n",
       " {'content': 'How about the Ashley hotel?', 'role': 'assistant'},\n",
       " {'content': 'Is the Ashley hotel a 3 star hotel?', 'role': 'user'},\n",
       " {'content': 'the ashley is actually a 2 star hotel.', 'role': 'assistant'},\n",
       " {'content': 'Does this hotel have rooms with a good view of the neighborhood?',\n",
       "  'role': 'user'}]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history = config.TEST_DS[0][\"messages\"][:-1]\n",
    "history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8bf86196",
   "metadata": {},
   "outputs": [],
   "source": [
    "output = assistant_agent._call(history=history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "58a96c11",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'content': 'You are a helpful travel assistant.', 'role': 'system'},\n",
       " {'content': \"I'm looking to stay at a 3 star hotel in the north.\",\n",
       "  'role': 'user'},\n",
       " {'content': 'Sorry, I have no results for that query. Would you like to try a different area of town?',\n",
       "  'role': 'assistant'},\n",
       " {'content': 'Are there any moderate priced hotels in the North?',\n",
       "  'role': 'user'},\n",
       " {'content': 'Yes I have two. Would you like me to book one?',\n",
       "  'role': 'assistant'},\n",
       " {'content': 'I need a hotel to include free parking; does either have that?',\n",
       "  'role': 'user'},\n",
       " {'content': 'Yes both of them have free parking.', 'role': 'assistant'},\n",
       " {'content': 'Which one would you recommend?', 'role': 'user'},\n",
       " {'content': 'How about the Ashley hotel?', 'role': 'assistant'},\n",
       " {'content': 'Is the Ashley hotel a 3 star hotel?', 'role': 'user'},\n",
       " {'content': 'the ashley is actually a 2 star hotel.', 'role': 'assistant'},\n",
       " {'content': 'Does this hotel have rooms with a good view of the neighborhood?',\n",
       "  'role': 'user'}]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1cf28e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llama_perf_context_print:        load time =    1700.49 ms\n",
      "llama_perf_context_print: prompt eval time =    1699.70 ms /   179 tokens (    9.50 ms per token,   105.31 tokens per second)\n",
      "llama_perf_context_print:        eval time =    5956.60 ms /   130 runs   (   45.82 ms per token,    21.82 tokens per second)\n",
      "llama_perf_context_print:       total time =    7670.70 ms /   309 tokens\n",
      "llama_perf_context_print:    graphs reused =        125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASSISTANT <think>\n",
      "Okay, the user is asking about the Ashley hotel's room views. I need to check if I have that information. From the conversation history, the user mentioned the hotel is 2-star, but didn't specify views. Since I don't have that data, I should inform them that I can't confirm the view and suggest they check with the hotel directly. Alternatively, maybe the hotel does have views, but I should be transparent. I should ask if they want me to look up the details or if they have other preferences. That way, I'm helpful without giving incorrect info.\n",
      "</think>\n",
      "\n",
      "I don't have specific information about the Ashley hotel's room views. To confirm if the rooms offer a good view of the neighborhood, I recommend checking the hotel's website directly or contacting them for detailed information. Would you like me to look up the hotel's details or suggest alternatives?\n",
      "USER Yes, the Ashley hotel does have some rooms that offer a good view of the neighborhood. However, I cannot guarantee which specific rooms have this view as it's subject to availability upon check-in. I would recommend contacting the hotel directly to inquire about this.\n",
      "\n",
      "Another option with a better view would be the North Star hotel. They have some rooms with a beautiful view of the city skyline. This is a 3-star hotel with a slightly higher price point but it could be worth checking out if that's a priority for you. Let me know if you would like me to book a room there.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Llama.generate: 175 prefix-match hit, remaining 137 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    1700.49 ms\n",
      "llama_perf_context_print: prompt eval time =     784.93 ms /   137 tokens (    5.73 ms per token,   174.54 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2251.30 ms /    49 runs   (   45.94 ms per token,    21.77 tokens per second)\n",
      "llama_perf_context_print:       total time =    3040.46 ms /   186 tokens\n",
      "llama_perf_context_print:    graphs reused =         46\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASSISTANT <think>\n",
      "Okay, the user is asking about the Ashley hotel's room views and has provided some information. They mentioned that the hotel does have rooms with a good view, but they can't guarantee which ones. They also mentioned another option, the North Star hotel, which has a better view and is 3-star. The user is looking for a recommendation and might be considering booking.\n",
      "\n",
      "I need to make sure my response is helpful and accurate. The user might be looking for a balance between price and view. The Ashley hotel is 2-star, so they might be concerned about the view being a priority. The North Star is 3-star, which is a bit more expensive but offers a better view. \n",
      "\n",
      "I should mention both options, clarify that the Ashley's view is not guaranteed, and suggest contacting the hotel for confirmation. Also, offer to book the North Star if they're okay with the higher price. Need to keep the tone friendly and helpful, ensuring they know the options available and\n",
      "USER Thank you for the information. I will consider both options and get back to you. Would it be possible for me to book a room with a view at the North Star hotel if available? And what is the price difference between the two hotels?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Llama.generate: 307 prefix-match hit, remaining 56 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    1700.49 ms\n",
      "llama_perf_context_print: prompt eval time =     377.38 ms /    56 tokens (    6.74 ms per token,   148.39 tokens per second)\n",
      "llama_perf_context_print:        eval time =    4965.05 ms /    97 runs   (   51.19 ms per token,    19.54 tokens per second)\n",
      "llama_perf_context_print:       total time =    5358.73 ms /   153 tokens\n",
      "llama_perf_context_print:    graphs reused =         93\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASSISTANT <think>\n",
      "Okay, the user is asking about booking a room with a view at the North Star hotel and the price difference between the two hotels. Let me start by confirming the availability. The North Star is a 3-star hotel with a better view, so I should mention that. The price difference is likely around $100-$150 per night, but I need to check if that's accurate. Wait, the user might not know the exact prices, so I should provide a general range. Also, the user wants to know if the view is available, so I should advise them to check with the hotel for confirmation. I should also keep the response friendly and offer further assistance if needed. Let me structure the response to include availability, price difference, and a suggestion to contact the hotel for details.\n",
      "</think>\n",
      "\n",
      "You're welcome! Here's a quick summary:  \n",
      "\n",
      "- **North Star Hotel**:  \n",
      "  - **Rating**: 3-star  \n",
      "  - **View**: Excellent\n",
      "USER Yes, I can check for a room with a view at the North Star hotel for you. The price difference between the two hotels is around $10-15 per night. The Ashley hotel is usually around $80-90 per night, while the North Star hotel is around $95-105 per night. Let me know if you would like me to proceed with checking availability and pricing for a room with a view at the North Star hotel.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Llama.generate: 359 prefix-match hit, remaining 104 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    1700.49 ms\n",
      "llama_perf_context_print: prompt eval time =     774.40 ms /   104 tokens (    7.45 ms per token,   134.30 tokens per second)\n",
      "llama_perf_context_print:        eval time =    2664.25 ms /    56 runs   (   47.58 ms per token,    21.02 tokens per second)\n",
      "llama_perf_context_print:       total time =    3445.37 ms /   160 tokens\n",
      "llama_perf_context_print:    graphs reused =         53\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASSISTANT <think>\n",
      "Okay, the user wants to book a room with a view at the North Star hotel. They mentioned the price difference is $10-15 per night. I need to confirm the exact prices and availability. The Ashley is $80-90, North Star is $95-105. I should check if the user wants me to proceed with the booking or if they need more info. Also, make sure to mention that availability depends on the date and time. Maybe suggest they check the hotel's website for real-time updates. Keep the tone helpful and clear.\n",
      "</think>\n",
      "\n",
      "I'll check the availability and pricing for a room with a view at the North Star hotel for you. The price difference between the two hotels is approximately **$1015 per night**, with the North Star Hotel being slightly more expensive. Let me confirm the exact rates and availability for your desired dates. Would you like me to proceed with the booking or need further details?\n",
      "USER I will consider both options and get back to you with my decision. Regarding the North Star hotel, could you please check the availability and pricing for a room with a view for two adults for two nights, starting from [insert desired check-in date]? Thank you.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Llama.generate: 458 prefix-match hit, remaining 63 prompt tokens to eval\n",
      "llama_perf_context_print:        load time =    1700.49 ms\n",
      "llama_perf_context_print: prompt eval time =     470.49 ms /    63 tokens (    7.47 ms per token,   133.90 tokens per second)\n",
      "llama_perf_context_print:        eval time =    3932.35 ms /    84 runs   (   46.81 ms per token,    21.36 tokens per second)\n",
      "llama_perf_context_print:       total time =    4412.02 ms /   147 tokens\n",
      "llama_perf_context_print:    graphs reused =         81\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ASSISTANT <think>\n",
      "Okay, the user wants to book a room at the North Star Hotel for two adults for two nights starting from a specific date. They mentioned they'll consider both options but need confirmation on the North Star's availability and pricing. \n",
      "\n",
      "First, I need to check if the user provided the check-in date. The previous message had [insert desired check-in date], so I should replace that with the actual date. But since the user hasn't specified the exact date yet, I should prompt them to provide it. \n",
      "\n",
      "Next, the user is asking for availability and pricing. I should confirm the dates and then check the hotel's rates. The price difference is $1015 per night, so I need to mention that. Also, the user might want to know if the view is available, so I should check that as well. \n",
      "\n",
      "Wait, the user hasn't given the check-in date yet. So I need to ask them for that. But in the previous message,\n",
      "USER Of course! I'll be happy to help you with that. I'll check the availability and pricing for a room with a view for two adults for two nights starting from [insert desired check-in date] at the North Star hotel. Let me know if you have a preferred room type or if you have any other specific requests. I'll get back to you as soon as I have the information.\n",
      "[{'content': 'You are a helpful travel assistant.', 'role': 'system'}, {'content': \"I'm looking to stay at a 3 star hotel in the north.\", 'role': 'user'}, {'content': 'Sorry, I have no results for that query. Would you like to try a different area of town?', 'role': 'assistant'}, {'content': 'Are there any moderate priced hotels in the North?', 'role': 'user'}, {'content': 'Yes I have two. Would you like me to book one?', 'role': 'assistant'}, {'content': 'I need a hotel to include free parking; does either have that?', 'role': 'user'}, {'content': 'Yes both of them have free parking.', 'role': 'assistant'}, {'content': 'Which one would you recommend?', 'role': 'user'}, {'content': 'How about the Ashley hotel?', 'role': 'assistant'}, {'content': 'Is the Ashley hotel a 3 star hotel?', 'role': 'user'}, {'content': 'the ashley is actually a 2 star hotel.', 'role': 'assistant'}, {'content': 'Does this hotel have rooms with a good view of the neighborhood?', 'role': 'user'}, {'role': 'system', 'content': \"<think>\\nOkay, the user is asking if the Ashley hotel has rooms with a good view of the neighborhood. Let me check the previous conversation. They initially asked for a 3-star hotel in the North, and I suggested the Ashley hotel, which they later found out is a 2-star. Now they want to know about the view.\\n\\nFirst, I need to confirm if the Ashley hotel offers views. Since I don't have that information, I should ask the user to check the hotel's website or contact them directly. But maybe the user expects me to know. Wait, in the previous messages, the user didn't mention anything about views, so I should be cautious. I should respond by asking if they want me to check the details or if they have specific preferences. Alternatively, I can mention that the hotel might have views and suggest they check with the hotel for confirmation. But since I can't access real-time data, it's safer to prompt them to verify. Also, the\"}, {'role': 'system', 'content': \"<think>\\nOkay, the user is asking about the Ashley hotel's room views. I need to check if I have that information. From the conversation history, the user mentioned the hotel is 2-star, but didn't specify views. Since I don't have that data, I should inform them that I can't confirm the view and suggest they check with the hotel directly. Alternatively, maybe the hotel does have views, but I should be transparent. I should ask if they want me to look up the details or if they have other preferences. That way, I'm helpful without giving incorrect info.\\n</think>\\n\\nI don't have specific information about the Ashley hotel's room views. To confirm if the rooms offer a good view of the neighborhood, I recommend checking the hotel's website directly or contacting them for detailed information. Would you like me to look up the hotel's details or suggest alternatives?\"}, {'role': 'user', 'content': \"Yes, the Ashley hotel does have some rooms that offer a good view of the neighborhood. However, I cannot guarantee which specific rooms have this view as it's subject to availability upon check-in. I would recommend contacting the hotel directly to inquire about this.\\n\\nAnother option with a better view would be the North Star hotel. They have some rooms with a beautiful view of the city skyline. This is a 3-star hotel with a slightly higher price point but it could be worth checking out if that's a priority for you. Let me know if you would like me to book a room there.\"}, {'role': 'system', 'content': \"<think>\\nOkay, the user is asking about the Ashley hotel's room views and has provided some information. They mentioned that the hotel does have rooms with a good view, but they can't guarantee which ones. They also mentioned another option, the North Star hotel, which has a better view and is 3-star. The user is looking for a recommendation and might be considering booking.\\n\\nI need to make sure my response is helpful and accurate. The user might be looking for a balance between price and view. The Ashley hotel is 2-star, so they might be concerned about the view being a priority. The North Star is 3-star, which is a bit more expensive but offers a better view. \\n\\nI should mention both options, clarify that the Ashley's view is not guaranteed, and suggest contacting the hotel for confirmation. Also, offer to book the North Star if they're okay with the higher price. Need to keep the tone friendly and helpful, ensuring they know the options available and\"}, {'role': 'user', 'content': 'Thank you for the information. I will consider both options and get back to you. Would it be possible for me to book a room with a view at the North Star hotel if available? And what is the price difference between the two hotels?'}, {'role': 'system', 'content': \"<think>\\nOkay, the user is asking about booking a room with a view at the North Star hotel and the price difference between the two hotels. Let me start by confirming the availability. The North Star is a 3-star hotel with a better view, so I should mention that. The price difference is likely around $100-$150 per night, but I need to check if that's accurate. Wait, the user might not know the exact prices, so I should provide a general range. Also, the user wants to know if the view is available, so I should advise them to check with the hotel for confirmation. I should also keep the response friendly and offer further assistance if needed. Let me structure the response to include availability, price difference, and a suggestion to contact the hotel for details.\\n</think>\\n\\nYou're welcome! Here's a quick summary:  \\n\\n- **North Star Hotel**:  \\n  - **Rating**: 3-star  \\n  - **View**: Excellent\"}, {'role': 'user', 'content': 'Yes, I can check for a room with a view at the North Star hotel for you. The price difference between the two hotels is around $10-15 per night. The Ashley hotel is usually around $80-90 per night, while the North Star hotel is around $95-105 per night. Let me know if you would like me to proceed with checking availability and pricing for a room with a view at the North Star hotel.'}, {'role': 'system', 'content': \"<think>\\nOkay, the user wants to book a room with a view at the North Star hotel. They mentioned the price difference is $10-15 per night. I need to confirm the exact prices and availability. The Ashley is $80-90, North Star is $95-105. I should check if the user wants me to proceed with the booking or if they need more info. Also, make sure to mention that availability depends on the date and time. Maybe suggest they check the hotel's website for real-time updates. Keep the tone helpful and clear.\\n</think>\\n\\nI'll check the availability and pricing for a room with a view at the North Star hotel for you. The price difference between the two hotels is approximately **$1015 per night**, with the North Star Hotel being slightly more expensive. Let me confirm the exact rates and availability for your desired dates. Would you like me to proceed with the booking or need further details?\"}, {'role': 'user', 'content': 'I will consider both options and get back to you with my decision. Regarding the North Star hotel, could you please check the availability and pricing for a room with a view for two adults for two nights, starting from [insert desired check-in date]? Thank you.'}, {'role': 'system', 'content': \"<think>\\nOkay, the user wants to book a room at the North Star Hotel for two adults for two nights starting from a specific date. They mentioned they'll consider both options but need confirmation on the North Star's availability and pricing. \\n\\nFirst, I need to check if the user provided the check-in date. The previous message had [insert desired check-in date], so I should replace that with the actual date. But since the user hasn't specified the exact date yet, I should prompt them to provide it. \\n\\nNext, the user is asking for availability and pricing. I should confirm the dates and then check the hotel's rates. The price difference is $1015 per night, so I need to mention that. Also, the user might want to know if the view is available, so I should check that as well. \\n\\nWait, the user hasn't given the check-in date yet. So I need to ask them for that. But in the previous message,\"}, {'role': 'user', 'content': \"Of course! I'll be happy to help you with that. I'll check the availability and pricing for a room with a view for two adults for two nights starting from [insert desired check-in date] at the North Star hotel. Let me know if you have a preferred room type or if you have any other specific requests. I'll get back to you as soon as I have the information.\"}]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'content': 'You are a helpful travel assistant.', 'role': 'system'},\n",
       " {'content': \"I'm looking to stay at a 3 star hotel in the north.\",\n",
       "  'role': 'user'},\n",
       " {'content': 'Sorry, I have no results for that query. Would you like to try a different area of town?',\n",
       "  'role': 'assistant'},\n",
       " {'content': 'Are there any moderate priced hotels in the North?',\n",
       "  'role': 'user'},\n",
       " {'content': 'Yes I have two. Would you like me to book one?',\n",
       "  'role': 'assistant'},\n",
       " {'content': 'I need a hotel to include free parking; does either have that?',\n",
       "  'role': 'user'},\n",
       " {'content': 'Yes both of them have free parking.', 'role': 'assistant'},\n",
       " {'content': 'Which one would you recommend?', 'role': 'user'},\n",
       " {'content': 'How about the Ashley hotel?', 'role': 'assistant'},\n",
       " {'content': 'Is the Ashley hotel a 3 star hotel?', 'role': 'user'},\n",
       " {'content': 'the ashley is actually a 2 star hotel.', 'role': 'assistant'},\n",
       " {'content': 'Does this hotel have rooms with a good view of the neighborhood?',\n",
       "  'role': 'user'},\n",
       " {'role': 'system',\n",
       "  'content': \"<think>\\nOkay, the user is asking if the Ashley hotel has rooms with a good view of the neighborhood. Let me check the previous conversation. They initially asked for a 3-star hotel in the North, and I suggested the Ashley hotel, which they later found out is a 2-star. Now they want to know about the view.\\n\\nFirst, I need to confirm if the Ashley hotel offers views. Since I don't have that information, I should ask the user to check the hotel's website or contact them directly. But maybe the user expects me to know. Wait, in the previous messages, the user didn't mention anything about views, so I should be cautious. I should respond by asking if they want me to check the details or if they have specific preferences. Alternatively, I can mention that the hotel might have views and suggest they check with the hotel for confirmation. But since I can't access real-time data, it's safer to prompt them to verify. Also, the\"},\n",
       " {'role': 'system',\n",
       "  'content': \"<think>\\nOkay, the user is asking about the Ashley hotel's room views. I need to check if I have that information. From the conversation history, the user mentioned the hotel is 2-star, but didn't specify views. Since I don't have that data, I should inform them that I can't confirm the view and suggest they check with the hotel directly. Alternatively, maybe the hotel does have views, but I should be transparent. I should ask if they want me to look up the details or if they have other preferences. That way, I'm helpful without giving incorrect info.\\n</think>\\n\\nI don't have specific information about the Ashley hotel's room views. To confirm if the rooms offer a good view of the neighborhood, I recommend checking the hotel's website directly or contacting them for detailed information. Would you like me to look up the hotel's details or suggest alternatives?\"},\n",
       " {'role': 'user',\n",
       "  'content': \"Yes, the Ashley hotel does have some rooms that offer a good view of the neighborhood. However, I cannot guarantee which specific rooms have this view as it's subject to availability upon check-in. I would recommend contacting the hotel directly to inquire about this.\\n\\nAnother option with a better view would be the North Star hotel. They have some rooms with a beautiful view of the city skyline. This is a 3-star hotel with a slightly higher price point but it could be worth checking out if that's a priority for you. Let me know if you would like me to book a room there.\"},\n",
       " {'role': 'system',\n",
       "  'content': \"<think>\\nOkay, the user is asking about the Ashley hotel's room views and has provided some information. They mentioned that the hotel does have rooms with a good view, but they can't guarantee which ones. They also mentioned another option, the North Star hotel, which has a better view and is 3-star. The user is looking for a recommendation and might be considering booking.\\n\\nI need to make sure my response is helpful and accurate. The user might be looking for a balance between price and view. The Ashley hotel is 2-star, so they might be concerned about the view being a priority. The North Star is 3-star, which is a bit more expensive but offers a better view. \\n\\nI should mention both options, clarify that the Ashley's view is not guaranteed, and suggest contacting the hotel for confirmation. Also, offer to book the North Star if they're okay with the higher price. Need to keep the tone friendly and helpful, ensuring they know the options available and\"},\n",
       " {'role': 'user',\n",
       "  'content': 'Thank you for the information. I will consider both options and get back to you. Would it be possible for me to book a room with a view at the North Star hotel if available? And what is the price difference between the two hotels?'},\n",
       " {'role': 'system',\n",
       "  'content': \"<think>\\nOkay, the user is asking about booking a room with a view at the North Star hotel and the price difference between the two hotels. Let me start by confirming the availability. The North Star is a 3-star hotel with a better view, so I should mention that. The price difference is likely around $100-$150 per night, but I need to check if that's accurate. Wait, the user might not know the exact prices, so I should provide a general range. Also, the user wants to know if the view is available, so I should advise them to check with the hotel for confirmation. I should also keep the response friendly and offer further assistance if needed. Let me structure the response to include availability, price difference, and a suggestion to contact the hotel for details.\\n</think>\\n\\nYou're welcome! Here's a quick summary:  \\n\\n- **North Star Hotel**:  \\n  - **Rating**: 3-star  \\n  - **View**: Excellent\"},\n",
       " {'role': 'user',\n",
       "  'content': 'Yes, I can check for a room with a view at the North Star hotel for you. The price difference between the two hotels is around $10-15 per night. The Ashley hotel is usually around $80-90 per night, while the North Star hotel is around $95-105 per night. Let me know if you would like me to proceed with checking availability and pricing for a room with a view at the North Star hotel.'},\n",
       " {'role': 'system',\n",
       "  'content': \"<think>\\nOkay, the user wants to book a room with a view at the North Star hotel. They mentioned the price difference is $10-15 per night. I need to confirm the exact prices and availability. The Ashley is $80-90, North Star is $95-105. I should check if the user wants me to proceed with the booking or if they need more info. Also, make sure to mention that availability depends on the date and time. Maybe suggest they check the hotel's website for real-time updates. Keep the tone helpful and clear.\\n</think>\\n\\nI'll check the availability and pricing for a room with a view at the North Star hotel for you. The price difference between the two hotels is approximately **$1015 per night**, with the North Star Hotel being slightly more expensive. Let me confirm the exact rates and availability for your desired dates. Would you like me to proceed with the booking or need further details?\"},\n",
       " {'role': 'user',\n",
       "  'content': 'I will consider both options and get back to you with my decision. Regarding the North Star hotel, could you please check the availability and pricing for a room with a view for two adults for two nights, starting from [insert desired check-in date]? Thank you.'},\n",
       " {'role': 'system',\n",
       "  'content': \"<think>\\nOkay, the user wants to book a room at the North Star Hotel for two adults for two nights starting from a specific date. They mentioned they'll consider both options but need confirmation on the North Star's availability and pricing. \\n\\nFirst, I need to check if the user provided the check-in date. The previous message had [insert desired check-in date], so I should replace that with the actual date. But since the user hasn't specified the exact date yet, I should prompt them to provide it. \\n\\nNext, the user is asking for availability and pricing. I should confirm the dates and then check the hotel's rates. The price difference is $1015 per night, so I need to mention that. Also, the user might want to know if the view is available, so I should check that as well. \\n\\nWait, the user hasn't given the check-in date yet. So I need to ask them for that. But in the previous message,\"},\n",
       " {'role': 'user',\n",
       "  'content': \"Of course! I'll be happy to help you with that. I'll check the availability and pricing for a room with a view for two adults for two nights starting from [insert desired check-in date] at the North Star hotel. Let me know if you have a preferred room type or if you have any other specific requests. I'll get back to you as soon as I have the information.\"}]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def start_conversation(\n",
    "    history: list[dict],\n",
    "    n: int = 5\n",
    ") -> list[dict]:\n",
    "    \n",
    "    for i in range(n):\n",
    "        assistant_response = assistant_agent._call(history=history)\n",
    "        history.append({\n",
    "            \"role\": \"system\",\n",
    "            \"content\": assistant_response,\n",
    "        })\n",
    "\n",
    "        user_response = user_agent._call(history=history)\n",
    "        history.append({\n",
    "            \"role\": \"user\",\n",
    "            \"content\": user_response,\n",
    "        })\n",
    "\n",
    "    return history\n",
    "\n",
    "start_conversation(history=history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f54f687a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "final-project-py3.13 (3.13.3)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
